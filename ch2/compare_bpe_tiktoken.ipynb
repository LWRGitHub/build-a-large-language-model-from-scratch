{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8546522-a1f2-411e-a550-6a61dc02694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install transformers\n",
    "# pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd04dbe2-c774-421c-a7ec-839ca788c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e55a3c2e-e34c-49d6-aeb0-080bcf333295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tik_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, world. Is this-- a test?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32560d45-d2aa-41e0-a313-7e292ffc2e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
     ]
    }
   ],
   "source": [
    "integers = tik_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57bf034e-90d8-413f-9a1b-e7b4493daee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world. Is this-- a test?\n"
     ]
    }
   ],
   "source": [
    "strings = tik_tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fbe0cc8-2fb2-4840-8e68-393149540806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(tik_tokenizer.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46bf898f-62bb-4560-9918-4f493a96add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpe_openai_gpt2 import get_encoder, download_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2dd2c480-9c52-4ad3-af30-f0c5c7a2e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching encoder.json: 1.04Mit [00:00, 1.24Mit/s]                                                   \n",
      "Fetching vocab.bpe: 457kit [00:00, 1.46Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "download_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4429863-1973-406a-81d1-7b3023e4f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_tokenizer = get_encoder(model_name=\"gpt2_model\", models_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "929d08be-ed1d-457f-b3c9-8b37f95abb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]\n"
     ]
    }
   ],
   "source": [
    "integers = orig_tokenizer.encode(text)\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7caa5a3-7272-4bd2-bc87-6ac5dbb3a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world. Is this-- a test?\n"
     ]
    }
   ],
   "source": [
    "string = orig_tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc61e325-0109-4487-93d3-8466c764c38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.42.3'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad5d4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "hf_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47e46aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 11, 995, 13, 1148, 428, 438, 257, 1332, 30]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer(strings)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34da0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "062ce513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5 ms ± 285 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f0a7406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.64 ms ± 532 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tik_tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b17a7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 6.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hf_tokenizer(raw_text)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e8757c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.5 ms ± 5.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hf_tokenizer(raw_text, max_length=5145, truncation=True)[\"input_ids\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
